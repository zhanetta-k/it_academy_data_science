{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN, LSTM, GRU: Number sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 15\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "numbers ='0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence():\n",
    "    \"\"\"Generate sequence:\n",
    "    y_1 = x_1\n",
    "    y_i = x_i + x_1\n",
    "    if y_i >=10, then y_i = y_i-10,\n",
    "    and split to X and Y.\"\"\"\n",
    "    \n",
    "    sequence = np.zeros(shape=((np.random.randint(1000, 1100)), 2), dtype=int)\n",
    "    for i in range(sequence.shape[0]):\n",
    "        sequence[i, 0] = np.random.randint(0, 10)\n",
    "    x_first = sequence[0, 0]\n",
    "    sequence[0, 1] = x_first\n",
    "    for i in range(1, sequence.shape[0]):\n",
    "        num = sequence[i, 0]\n",
    "        y_i = num + x_first\n",
    "        if y_i >= 10:\n",
    "            y_i = y_i - 10\n",
    "        sequence[i, 1] = y_i\n",
    "    sequence = torch.tensor(sequence).long()\n",
    "    X = sequence[:, 0]\n",
    "    Y = sequence[:, 1]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shape: torch.Size([1051])\n"
     ]
    }
   ],
   "source": [
    "X, Y = generate_sequence()\n",
    "print(f'Sequence shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_data = DataLoader(train_data, batch_size, shuffle=True)\n",
    "val_data = DataLoader(val_data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexRNN(torch.nn.Module):\n",
    "    def __init__(self, rnnClass, dictionary_size, embedding_size,\n",
    "                 num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = torch.nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
    "        self.output = torch.nn.Linear(num_hiddens, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        embed = self.embedding(X)\n",
    "        output, hidden = self.hidden(embed)\n",
    "        output = self.output(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train_data, val_data, \n",
    "                criterion, optimizer):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        train_acc = []\n",
    "        train_loss = []\n",
    "        val_acc = []\n",
    "        val_loss = []\n",
    "\n",
    "        model.train()\n",
    "        for x_b, y_b in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            answers = model(x_b)  # answers: 32 x 10\n",
    "            loss = criterion(answers, y_b)  # y: 32\n",
    "            train_loss.append(loss.item())\n",
    "            batch_acc = (answers.argmax(dim=1) == y_b)\n",
    "            train_acc.append(batch_acc.sum().item() / batch_acc.shape[0])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_b, y_b in val_data:\n",
    "                answers = model(x_b)\n",
    "                loss = criterion(answers, y_b)\n",
    "                val_loss.append(loss.item())\n",
    "                batch_acc = (answers.argmax(dim=1) == y_b)\n",
    "                val_acc.append(batch_acc.sum().item() / batch_acc.shape[0])\n",
    "\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        print(\"Train loss: {:.3f} Train accuracy: {:.3f}\".format(np.mean(train_loss),\n",
    "                                                                 (np.mean(train_acc))),\n",
    "                                                                  end=\" |  \")\n",
    "        print(\"Validation loss: {:.3f} Validation accuracy: {:.3f}\".format(np.mean(val_loss),\n",
    "                                                             (np.mean(val_acc))))\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = FlexRNN(torch.nn.RNN, len(numbers), 28, 128, len(numbers)).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train loss: 1.925 Train accuracy: 0.641 |  Validation loss: 1.531 Validation accuracy: 0.996\n",
      "Epoch 1\n",
      "Train loss: 1.229 Train accuracy: 0.998 |  Validation loss: 0.911 Validation accuracy: 1.000\n",
      "Epoch 2\n",
      "Train loss: 0.696 Train accuracy: 0.999 |  Validation loss: 0.474 Validation accuracy: 1.000\n",
      "Epoch 3\n",
      "Train loss: 0.345 Train accuracy: 0.999 |  Validation loss: 0.236 Validation accuracy: 1.000\n",
      "Epoch 4\n",
      "Train loss: 0.181 Train accuracy: 0.999 |  Validation loss: 0.126 Validation accuracy: 1.000\n",
      "Epoch 5\n",
      "Train loss: 0.106 Train accuracy: 0.999 |  Validation loss: 0.078 Validation accuracy: 1.000\n",
      "Epoch 6\n",
      "Train loss: 0.071 Train accuracy: 0.999 |  Validation loss: 0.053 Validation accuracy: 1.000\n",
      "Epoch 7\n",
      "Train loss: 0.053 Train accuracy: 0.999 |  Validation loss: 0.040 Validation accuracy: 1.000\n",
      "Epoch 8\n",
      "Train loss: 0.042 Train accuracy: 0.999 |  Validation loss: 0.031 Validation accuracy: 1.000\n",
      "Epoch 9\n",
      "Train loss: 0.035 Train accuracy: 0.999 |  Validation loss: 0.026 Validation accuracy: 1.000\n",
      "Epoch 10\n",
      "Train loss: 0.031 Train accuracy: 0.999 |  Validation loss: 0.021 Validation accuracy: 1.000\n",
      "Epoch 11\n",
      "Train loss: 0.027 Train accuracy: 0.999 |  Validation loss: 0.018 Validation accuracy: 1.000\n",
      "Epoch 12\n",
      "Train loss: 0.024 Train accuracy: 0.999 |  Validation loss: 0.016 Validation accuracy: 1.000\n",
      "Epoch 13\n",
      "Train loss: 0.022 Train accuracy: 0.999 |  Validation loss: 0.014 Validation accuracy: 1.000\n",
      "Epoch 14\n",
      "Train loss: 0.020 Train accuracy: 0.999 |  Validation loss: 0.012 Validation accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "train_model(model_rnn, num_epochs, train_data, val_data,\n",
    "            criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999\n",
      "Validation number: 'tensor([6, 2, 5, 6, 4, 8, 5, 8, 6, 0, 6, 0, 2, 2])'\n",
      "True number: 'tensor([8, 2, 5, 6, 4, 8, 5, 8, 6, 0, 6, 0, 2, 2])'\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(5, 15)\n",
    "results = model_rnn(X).argmax(dim=1)\n",
    "acc = (results == Y).flatten()\n",
    "acc = (acc.sum() / acc.shape[0])\n",
    "output = results[:idx]\n",
    "true_input = Y[:idx]\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Validation number: '{output}'\")\n",
    "print(f\"True number: '{true_input}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = FlexRNN(torch.nn.LSTM, len(numbers), 28, 128, len(numbers)).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train loss: 2.177 Train accuracy: 0.564 |  Validation loss: 2.024 Validation accuracy: 0.795\n",
      "Epoch 1\n",
      "Train loss: 1.867 Train accuracy: 0.882 |  Validation loss: 1.623 Validation accuracy: 0.872\n",
      "Epoch 2\n",
      "Train loss: 1.331 Train accuracy: 0.949 |  Validation loss: 0.982 Validation accuracy: 1.000\n",
      "Epoch 3\n",
      "Train loss: 0.718 Train accuracy: 0.999 |  Validation loss: 0.471 Validation accuracy: 1.000\n",
      "Epoch 4\n",
      "Train loss: 0.332 Train accuracy: 0.999 |  Validation loss: 0.218 Validation accuracy: 1.000\n",
      "Epoch 5\n",
      "Train loss: 0.167 Train accuracy: 0.999 |  Validation loss: 0.120 Validation accuracy: 1.000\n",
      "Epoch 6\n",
      "Train loss: 0.095 Train accuracy: 0.999 |  Validation loss: 0.079 Validation accuracy: 1.000\n",
      "Epoch 7\n",
      "Train loss: 0.070 Train accuracy: 0.999 |  Validation loss: 0.059 Validation accuracy: 1.000\n",
      "Epoch 8\n",
      "Train loss: 0.053 Train accuracy: 0.999 |  Validation loss: 0.047 Validation accuracy: 1.000\n",
      "Epoch 9\n",
      "Train loss: 0.048 Train accuracy: 0.999 |  Validation loss: 0.038 Validation accuracy: 1.000\n",
      "Epoch 10\n",
      "Train loss: 0.038 Train accuracy: 0.999 |  Validation loss: 0.032 Validation accuracy: 1.000\n",
      "Epoch 11\n",
      "Train loss: 0.036 Train accuracy: 0.999 |  Validation loss: 0.028 Validation accuracy: 1.000\n",
      "Epoch 12\n",
      "Train loss: 0.029 Train accuracy: 0.999 |  Validation loss: 0.025 Validation accuracy: 1.000\n",
      "Epoch 13\n",
      "Train loss: 0.029 Train accuracy: 0.999 |  Validation loss: 0.022 Validation accuracy: 1.000\n",
      "Epoch 14\n",
      "Train loss: 0.025 Train accuracy: 0.999 |  Validation loss: 0.020 Validation accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "train_model(model_lstm, num_epochs, train_data, val_data, \n",
    "            criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999\n",
      "Validation number: 'tensor([6, 2, 5, 6, 4, 8, 5, 8])'\n",
      "True number: 'tensor([8, 2, 5, 6, 4, 8, 5, 8])'\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(5, 15)\n",
    "results = model_rnn(X).argmax(dim=1)\n",
    "acc = (results == Y).flatten()\n",
    "acc = (acc.sum() / acc.shape[0])\n",
    "output = results[:idx]\n",
    "true_input = Y[:idx]\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Validation number: '{output}'\")\n",
    "print(f\"True number: '{true_input}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = FlexRNN(torch.nn.GRU, len(numbers), 28, 128, len(numbers)).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_gru.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train loss: 2.059 Train accuracy: 0.602 |  Validation loss: 1.813 Validation accuracy: 0.901\n",
      "Epoch 1\n",
      "Train loss: 1.586 Train accuracy: 0.946 |  Validation loss: 1.286 Validation accuracy: 0.996\n",
      "Epoch 2\n",
      "Train loss: 0.994 Train accuracy: 0.998 |  Validation loss: 0.672 Validation accuracy: 1.000\n",
      "Epoch 3\n",
      "Train loss: 0.469 Train accuracy: 0.999 |  Validation loss: 0.280 Validation accuracy: 1.000\n",
      "Epoch 4\n",
      "Train loss: 0.203 Train accuracy: 0.999 |  Validation loss: 0.127 Validation accuracy: 1.000\n",
      "Epoch 5\n",
      "Train loss: 0.104 Train accuracy: 0.999 |  Validation loss: 0.071 Validation accuracy: 1.000\n",
      "Epoch 6\n",
      "Train loss: 0.064 Train accuracy: 0.999 |  Validation loss: 0.047 Validation accuracy: 1.000\n",
      "Epoch 7\n",
      "Train loss: 0.048 Train accuracy: 0.999 |  Validation loss: 0.035 Validation accuracy: 1.000\n",
      "Epoch 8\n",
      "Train loss: 0.037 Train accuracy: 0.999 |  Validation loss: 0.028 Validation accuracy: 1.000\n",
      "Epoch 9\n",
      "Train loss: 0.033 Train accuracy: 0.999 |  Validation loss: 0.023 Validation accuracy: 1.000\n",
      "Epoch 10\n",
      "Train loss: 0.030 Train accuracy: 0.999 |  Validation loss: 0.020 Validation accuracy: 1.000\n",
      "Epoch 11\n",
      "Train loss: 0.024 Train accuracy: 0.999 |  Validation loss: 0.017 Validation accuracy: 1.000\n",
      "Epoch 12\n",
      "Train loss: 0.019 Train accuracy: 0.999 |  Validation loss: 0.015 Validation accuracy: 1.000\n",
      "Epoch 13\n",
      "Train loss: 0.021 Train accuracy: 0.999 |  Validation loss: 0.013 Validation accuracy: 1.000\n",
      "Epoch 14\n",
      "Train loss: 0.018 Train accuracy: 0.999 |  Validation loss: 0.012 Validation accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "train_model(model_gru, num_epochs, train_data, val_data, \n",
    "            criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999\n",
      "Validation number: 'tensor([6, 2, 5, 6, 4, 8, 5, 8, 6, 0, 6])'\n",
      "True number: 'tensor([8, 2, 5, 6, 4, 8, 5, 8, 6, 0, 6])'\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(5, 15)\n",
    "results = model_rnn(X).argmax(dim=1)\n",
    "acc = (results == Y).flatten()\n",
    "acc = (acc.sum() / acc.shape[0])\n",
    "output = results[:idx]\n",
    "true_input = Y[:idx]\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Validation number: '{output}'\")\n",
    "print(f\"True number: '{true_input}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
