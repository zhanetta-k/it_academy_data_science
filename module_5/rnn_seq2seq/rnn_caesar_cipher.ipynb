{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: Caesar cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.05\n",
    "file_name = './data/article.txt'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_offset = 3\n",
    "alphabet = ('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ')\n",
    "shifted_alphabet = alphabet[caesar_offset:] + alphabet[:caesar_offset]\n",
    "\n",
    "char_to_index = {c: i for i, c in enumerate(alphabet)}\n",
    "index_to_char = list(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(txt_path):\n",
    "    \"\"\"Preprocess text.\"\"\"\n",
    "    with open(txt_path, encoding='utf-8') as txt_file:\n",
    "        text = txt_file.read()\n",
    "        text = re.sub('[^a-zA-Z\\. ]', ' ', text)\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        text = re.sub('( s )', 's ', text)\n",
    "\n",
    "        data = text.replace('\\n', ' ').split(\".\")\n",
    "        data = [x.strip(' ') for x in data]\n",
    "    print(f'Number of strings in data list: {len(data)}')\n",
    "    return data\n",
    "\n",
    "def encrypt_text(text, offset, alphabet=alphabet,\n",
    "                 shifted_alphabet=shifted_alphabet):\n",
    "    table = str.maketrans(alphabet, shifted_alphabet)\n",
    "    encrypted_text = [text[i].translate(table) for i in range(len(text))]\n",
    "    return encrypted_text\n",
    "\n",
    "\n",
    "def decrypt_text(encrypted_text, alphabet=alphabet,\n",
    "                 shifted_alphabet=shifted_alphabet):\n",
    "    table = str.maketrans(shifted_alphabet, alphabet)\n",
    "    decrypted_text = [encrypted_text[i].translate(table) for i in range(len(encrypted_text))]\n",
    "    return decrypted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings in data list: 418\n"
     ]
    }
   ],
   "source": [
    "data = load_and_preprocess(file_name)\n",
    "encrypted = encrypt_text(data, caesar_offset)\n",
    "decrypted = decrypt_text(encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decrypted_text</th>\n",
       "      <th>Encrypted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Childrens experiences and propaganda</td>\n",
       "      <td>FkloguhqvchAshulhqfhvcdqgcsursdjdqgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curator Ian Cooke discusses the ways in which ...</td>\n",
       "      <td>FxudwrucLdqcFrrnhcglvfxvvhvcwkhczdBvclqczklfkc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Children were affected by the First World War ...</td>\n",
       "      <td>FkloguhqczhuhcdiihfwhgceBcwkhcIluvwcZruogcZduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the first time war impacted on whole popul...</td>\n",
       "      <td>Irucwkhciluvwcwlphczduclpsdfwhgcrqczkrohcsrsxo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technological innovations brought the threat o...</td>\n",
       "      <td>Whfkqrorjlfdoclqqrydwlrqvceurxjkwcwkhcwkuhdwcr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Decrypted_text  \\\n",
       "0               Childrens experiences and propaganda   \n",
       "1  Curator Ian Cooke discusses the ways in which ...   \n",
       "2  Children were affected by the First World War ...   \n",
       "3  For the first time war impacted on whole popul...   \n",
       "4  Technological innovations brought the threat o...   \n",
       "\n",
       "                                      Encrypted_text  \n",
       "0               FkloguhqvchAshulhqfhvcdqgcsursdjdqgd  \n",
       "1  FxudwrucLdqcFrrnhcglvfxvvhvcwkhczdBvclqczklfkc...  \n",
       "2  FkloguhqczhuhcdiihfwhgceBcwkhcIluvwcZruogcZduc...  \n",
       "3  Irucwkhciluvwcwlphczduclpsdfwhgcrqczkrohcsrsxo...  \n",
       "4  Whfkqrorjlfdoclqqrydwlrqvceurxjkwcwkhcwkuhdwcr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Decrypted_text': decrypted,'Encrypted_text': encrypted})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/article_decr_encr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "text = [[c for c in ph] for ph in data]\n",
    "Y = [[char_to_index[ch] for ch in line] for line in data]\n",
    "X = [[i + caesar_offset for i in line] for line in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: torch.Size([418, 374])\n",
      "X shape: torch.Size([418, 374])\n"
     ]
    }
   ],
   "source": [
    "# Padding\n",
    "Y_tensor = [torch.as_tensor(seq) for seq in Y]\n",
    "Y_padded = pad_sequence(Y_tensor, batch_first=True)\n",
    "\n",
    "X_tensor = [torch.as_tensor(seq) for seq in X]\n",
    "X_padded = pad_sequence(X_tensor, batch_first=True)\n",
    "\n",
    "print(f\"Y shape: {Y_padded.shape}\")\n",
    "print(f\"X shape: {X_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_padded, Y_padded)\n",
    "data = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(torch.nn.Module):\n",
    "    def __init__(self, dictionary_size, embedding_size,\n",
    "                 num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = torch.nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.rnn = torch.nn.RNN(embedding_size, num_hiddens, batch_first=True)\n",
    "        self.output = torch.nn.Linear(num_hiddens, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        embed = self.embedding(X)\n",
    "        output, hidden = self.rnn(embed)\n",
    "        output = self.output(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicRNN(len(char_to_index) + caesar_offset, 28, 64,\n",
    "                 len(char_to_index) + caesar_offset).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   Time 4.595    Train Loss: 0.840\n",
      "Epoch 1   Time 3.222    Train Loss: 0.038\n",
      "Epoch 2   Time 1.995    Train Loss: 0.011\n",
      "Epoch 3   Time 2.338    Train Loss: 0.004\n",
      "Epoch 4   Time 2.127    Train Loss: 0.002\n",
      "Epoch 5   Time 2.290    Train Loss: 0.001\n",
      "Epoch 6   Time 2.446    Train Loss: 0.001\n",
      "Epoch 7   Time 2.603    Train Loss: 0.001\n",
      "Epoch 8   Time 2.655    Train Loss: 0.000\n",
      "Epoch 9   Time 3.003    Train Loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_b, y_b in data:\n",
    "      optimizer.zero_grad()\n",
    "      y_b = y_b.view(1, -1).squeeze()\n",
    "      answers = model(X_b)\n",
    "      answers = answers.view(-1, len(alphabet) + caesar_offset)\n",
    "      loss = criterion(answers, y_b)\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}   Time {:.3f}    Train Loss: {:.3f}\".format(epoch, time.time() - start,\n",
    "                                                                train_loss / train_passed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.000\n",
      "Validation sentence: 'The hope that love could bring to the soldier on the front lines is captured '\n",
      "True sentence: 'The hope that love could bring to the soldier on the front lines is captured '\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(X_padded) - 1)\n",
    "results = model(X_padded.to(device)).argmax(dim=2)\n",
    "acc = (results == Y_padded.to(device)).flatten()\n",
    "acc = (acc.sum() / acc.shape[0])\n",
    "out_sentence = \"\".join([index_to_char[i] for i in results[idx]])\n",
    "true_sentence = \"\".join([index_to_char[i] for i in Y_padded[idx]])\n",
    "\n",
    "print(f\"Train accuracy: {acc:.3f}\")\n",
    "print(f\"Validation sentence: '{out_sentence[:77]}'\")\n",
    "print(f\"True sentence: '{true_sentence[:77]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Taking a phrase from outside the dataset:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"Language changes very subtly whenever speakers come into\n",
    "contact with each other. No two individuals speak identically: people from\n",
    "different geographical places clearly speak differently, but even within\n",
    "the same small community there are variations according to a speaker's age,\n",
    "gender, ethnicity and social and educational background. Through our interactions\n",
    "with these different speakers, we encounter new words, expressions and\n",
    "pronunciations and integrate them into our own speech.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = re.sub('[^a-zA-Z ]', ' ', sentence)\n",
    "    sentence = re.sub('\\s+', ' ', sentence)\n",
    "    sentence = re.sub('( s )', 's ', sentence)\n",
    "    return sentence\n",
    "\n",
    "sentence = preprocess(sentence)\n",
    "encrypted_sentence = encrypt_text(sentence, caesar_offset, alphabet=alphabet)\n",
    "encrypted_idx = [char_to_index[char] + caesar_offset for char in sentence]\n",
    "\n",
    "result = model(torch.tensor([encrypted_idx]).to(device)).argmax(dim=2)\n",
    "Y = torch.tensor([[char_to_index[ch] for ch in line] for line in sentence])\n",
    "acc = (result == Y.reshape(1, -1).to(device)).flatten()\n",
    "acc = (acc.sum() / acc.shape[0])\n",
    "decrypted_sentence = \"\".join([alphabet[i] for i in result.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n",
      "_________________\n",
      "Encrypted sentence:\n",
      "OdqjxdjhcfkdqjhvcyhuBcvxewoBczkhqhyhucvshdnhuvcfrphclqwrcfrqwdfwczlwkchdfkcrwkhucQrcwzrclqglylgxdovcvshdnclghqwlfdooBcshrsohciurpcgli\n",
      "ihuhqwcjhrjudsklfdocsodfhvcfohduoBcvshdncgliihuhqwoBcexwchyhqczlwklqcwkhcvdphcvpdoocfrppxqlwBcwkhuhcduhcyduldwlrqvcdffruglqjcwrcdcvsh\n",
      "dnhuvcdjhcjhqghuchwkqlflwBcdqgcvrfldocdqgchgxfdwlrqdocedfnjurxqgcWkurxjkcrxuclqwhudfwlrqvczlwkcwkhvhcgliihuhqwcvshdnhuvczhchqfrxqwhuc\n",
      "qhzczrugvchAsuhvvlrqvcdqgcsurqxqfldwlrqvcdqgclqwhjudwhcwkhpclqwrcrxucrzqcvshhfkc\n",
      "-----------------\n",
      "Decrypted sentence:\n",
      "Language changes very subtly whenever speakers come into contact with each other No two individuals speak identically people from dif\n",
      "ferent geographical places clearly speak differently but even within the same small community there are variations according to a spe\n",
      "akers age gender ethnicity and social and educational background Through our interactions with these different speakers we encounter \n",
      "new words expressions and pronunciations and integrate them into our own speech \n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(\"_\" * 17)\n",
    "length = 133\n",
    "print(\"Encrypted sentence:\")\n",
    "for i in range(0, len(encrypted_sentence), length):\n",
    "    print (f\"{''.join(encrypted_sentence[i: i+length])}\")\n",
    "print(\"-\" * 17)\n",
    "print(\"Decrypted sentence:\")\n",
    "for i in range(0, len(decrypted_sentence), length):\n",
    "    print (f\"{decrypted_sentence[i: i+length]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
